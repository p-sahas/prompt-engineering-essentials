{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 02: Prompt Structure Patterns\n",
        "\n",
        "**Objectives:**\n",
        "- Compare unstructured vs structured prompts\n",
        "- Use skeleton.v1 and zero_shot.v1 from central catalog\n",
        "- Measure token efficiency and response quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from utils.prompts import render\n",
        "from utils.llm_client import LLMClient\n",
        "from utils.logging_utils import log_llm_call\n",
        "from utils.router import pick_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unstructured vs Skeleton Pattern\n",
        "\n",
        "Compare a vague prompt with a structured skeleton prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== UNSTRUCTURED PROMPT ===\n",
            "Tokens: 226\n",
            "Result: CloudSync Pro 2.5.0, releasing in Q1 2025, is an enterprise-grade file synchronization and collaboration platform for distributed teams. Key features include real-time file syncing with low latency and adaptive bandwidth management, robust version control with history retention, comparison, rollback, and branching, and strong security and compliance measures. It also offers offline mode and batch processing capabilities.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = pick_model('google', 'general')\n",
        "client = LLMClient('google', model)\n",
        "\n",
        "# Load context\n",
        "with open('../data/tiny_corpus/02_product_specs.md') as f:\n",
        "    context = f.read()[:1000]\n",
        "\n",
        "# Approach 1: Unstructured prompt (baseline)\n",
        "unstructured_prompt = f\"Summarize this product:\\n\\n{context}\"\n",
        "\n",
        "response_unstructured = client.chat(\n",
        "    [{'role': 'user', 'content': unstructured_prompt}], \n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print('=== UNSTRUCTURED PROMPT ===')\n",
        "print(f'Tokens: {response_unstructured[\"usage\"][\"total_est\"]}')\n",
        "print(f'Result: {response_unstructured[\"text\"]}\\n')\n",
        "log_llm_call('openai', model, 'unstructured', response_unstructured['latency_ms'], response_unstructured['usage'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SKELETON PATTERN ===\n",
            "Tokens: 267\n",
            "Result: CloudSync Pro is an enterprise-grade file synchronization and collaboration platform enabling secure, real-time file sharing for distributed teams. It features advanced version control with conflict resolution, ensuring data integrity and efficient collaboration. With robust security and compliance features, CloudSync Pro provides a reliable solution for businesses needing to manage and protect their data.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Approach 2: Skeleton pattern (structured)\n",
        "prompt_text, spec = render(\n",
        "    'skeleton.v1',\n",
        "    role='Technical summarizer',\n",
        "    task='Summarize CloudSync Pro in 3 sentences',\n",
        "    context=context,\n",
        "    constraints='Max 3 sentences, focus on value proposition',\n",
        "    format='Plain text',\n",
        "    checks='Exactly 3 sentences'\n",
        ")\n",
        "\n",
        "response_skeleton = client.chat(\n",
        "    [{'role': 'user', 'content': prompt_text}], \n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "print('=== SKELETON PATTERN ===')\n",
        "print(f'Tokens: {response_skeleton[\"usage\"][\"total_est\"]}')\n",
        "print(f'Result: {response_skeleton[\"text\"]}\\n')\n",
        "log_llm_call('openai', model, 'skeleton', response_skeleton['latency_ms'], response_skeleton['usage'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zero-Shot Pattern\n",
        "\n",
        "Demonstrate the zero_shot.v1 pattern for classification tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== UNSTRUCTURED CLASSIFICATION ===\n",
            "Result: This feedback is overwhelmingly **negative**.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "*   **\"Extremely disappointed\"**: This is a strong negative sentiment.\n",
            "*   **\"Sync is slow\"**: This is a performance issue.\n",
            "*   **\"Files get corrupted\"**: This is a serious data integrity issue.\n",
            "*   **\"Customer support never responds\"**: This is a customer service failure.\n",
            "\n",
            "All of these points indicate a very poor user experience.\n",
            "\n",
            "\n",
            "=== ZERO-SHOT PATTERN ===\n",
            "Result: negative\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot classification example\n",
        "customer_feedback = \"\"\"I've been using CloudSync Pro for 3 months and I'm extremely disappointed. \n",
        "The sync is slow, files get corrupted, and customer support never responds.\"\"\"\n",
        "\n",
        "# Unstructured approach\n",
        "unstructured_classify = f\"Is this feedback positive or negative?\\n\\n{customer_feedback}\"\n",
        "\n",
        "response_unstructured_cls = client.chat(\n",
        "    [{'role': 'user', 'content': unstructured_classify}], \n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print('=== UNSTRUCTURED CLASSIFICATION ===')\n",
        "print(f'Result: {response_unstructured_cls[\"text\"]}\\n')\n",
        "\n",
        "# Zero-shot structured approach\n",
        "prompt_text, spec = render(\n",
        "    'zero_shot.v1',\n",
        "    role='customer feedback analyzer',\n",
        "    instruction='Classify the sentiment of the customer feedback',\n",
        "    constraints='Return only one word: positive, negative, or neutral',\n",
        "    format='Single word'\n",
        ")\n",
        "\n",
        "full_prompt = f\"{prompt_text}\\n\\nFeedback: {customer_feedback}\"\n",
        "\n",
        "response_zero_shot = client.chat(\n",
        "    [{'role': 'user', 'content': full_prompt}], \n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "print('=== ZERO-SHOT PATTERN ===')\n",
        "print(f'Result: {response_zero_shot[\"text\"]}\\n')\n",
        "log_llm_call('openai', model, 'zero_shot_classify', response_zero_shot['latency_ms'], response_zero_shot['usage'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison & Analysis\n",
        "\n",
        "Compare token efficiency and response quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Approach       Use Case  Prompt Tokens (est)  Total Tokens (est)                            Pros                    Cons\n",
            "     Unstructured  Summarization                  223                 226           Simple, fast to write   Unpredictable outputs\n",
            " Skeleton Pattern  Summarization                  264                 267 Clear structure, better control    More verbose prompts\n",
            "Zero-Shot Pattern Classification                   79                  82  Precise outputs, easy to parse Needs clear constraints\n",
            "\n",
            "=== KEY INSIGHTS ===\n",
            "1. Skeleton pattern uses ~41 more prompt tokens but provides better control\n",
            "2. Zero-shot pattern produces consistent, parseable outputs\n",
            "3. Structured patterns reduce need for retry/validation (lower total cost)\n",
            "4. Trade-off: Prompt complexity vs Output reliability\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create comparison table\n",
        "comparison = pd.DataFrame({\n",
        "    'Approach': ['Unstructured', 'Skeleton Pattern', 'Zero-Shot Pattern'],\n",
        "    'Use Case': ['Summarization', 'Summarization', 'Classification'],\n",
        "    'Prompt Tokens (est)': [\n",
        "        response_unstructured['usage']['input_tokens_est'],\n",
        "        response_skeleton['usage']['input_tokens_est'],\n",
        "        response_zero_shot['usage']['input_tokens_est']\n",
        "    ],\n",
        "    'Total Tokens (est)': [\n",
        "        response_unstructured['usage']['total_est'],\n",
        "        response_skeleton['usage']['total_est'],\n",
        "        response_zero_shot['usage']['total_est']\n",
        "    ],\n",
        "    'Pros': [\n",
        "        'Simple, fast to write',\n",
        "        'Clear structure, better control',\n",
        "        'Precise outputs, easy to parse'\n",
        "    ],\n",
        "    'Cons': [\n",
        "        'Unpredictable outputs',\n",
        "        'More verbose prompts',\n",
        "        'Needs clear constraints'\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "print('\\n=== KEY INSIGHTS ===')\n",
        "print(f'1. Skeleton pattern uses ~{response_skeleton[\"usage\"][\"input_tokens_est\"] - response_unstructured[\"usage\"][\"input_tokens_est\"]} more prompt tokens but provides better control')\n",
        "print(f'2. Zero-shot pattern produces consistent, parseable outputs')\n",
        "print(f'3. Structured patterns reduce need for retry/validation (lower total cost)')\n",
        "print(f'4. Trade-off: Prompt complexity vs Output reliability')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Structured prompts > Unstructured**: Higher upfront prompt tokens, but more reliable outputs\n",
        "2. **Skeleton pattern**: Best for complex tasks requiring clear role, task, context, constraints\n",
        "3. **Zero-shot pattern**: Perfect for classification tasks with predictable outputs\n",
        "4. **Token efficiency**: Measured by total cost including retries, not just prompt tokens\n",
        "5. **Central catalog**: Using `utils/prompts.py` ensures consistency across your codebase\n",
        "\n",
        "**When to use each:**\n",
        "- **Unstructured**: Quick experiments, exploratory queries\n",
        "- **Skeleton**: Complex generation tasks, content creation, summarization\n",
        "- **Zero-shot**: Classification, labeling, structured extraction\n",
        "\n",
        "**Next:** `03_zero_few_cot_tot.ipynb`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
